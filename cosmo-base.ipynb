{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9662866,"sourceType":"datasetVersion","datasetId":5903886}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-10-19T01:30:35.778444Z","iopub.execute_input":"2024-10-19T01:30:35.779360Z","iopub.status.idle":"2024-10-19T01:30:35.784480Z","shell.execute_reply.started":"2024-10-19T01:30:35.779316Z","shell.execute_reply":"2024-10-19T01:30:35.783522Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, random_split\nimport torch.optim as optim\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T02:34:48.271395Z","iopub.execute_input":"2024-10-19T02:34:48.272219Z","iopub.status.idle":"2024-10-19T02:34:48.277850Z","shell.execute_reply.started":"2024-10-19T02:34:48.272170Z","shell.execute_reply":"2024-10-19T02:34:48.276792Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset\nimport torchvision.transforms.functional as TF\nimport random\n\nclass FloodDataset(Dataset):\n    def __init__(self, csv_file, img_dir, mask_dir, img_transform=None, mask_transform=None, augment=False):\n        self.data = pd.read_csv(csv_file)\n        self.img_dir = img_dir\n        self.mask_dir = mask_dir\n        self.img_transform = img_transform\n        self.mask_transform = mask_transform\n        self.augment = augment\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.img_dir, self.data.iloc[idx, 0])\n        mask_name = os.path.join(self.mask_dir, self.data.iloc[idx, 1])\n        \n        image = Image.open(img_name).convert(\"RGB\")\n        mask = Image.open(mask_name).convert(\"L\")  # Convert mask to grayscale\n        \n        if self.augment:\n            image, mask = self.apply_augmentation(image, mask)\n        \n        if self.img_transform:\n            image = self.img_transform(image)\n        \n        if self.mask_transform:\n            mask = self.mask_transform(mask)\n        else:\n            mask = TF.to_tensor(mask)\n        \n        # Ensure mask is binary\n        mask = (mask > 0.5).float()\n        \n        return image, mask\n\n    def apply_augmentation(self, image, mask):\n        # Random horizontal flipping\n        if random.random() > 0.5:\n            image = TF.hflip(image)\n            mask = TF.hflip(mask)\n        \n        # Random vertical flipping\n        if random.random() > 0.5:\n            image = TF.vflip(image)\n            mask = TF.vflip(mask)\n        \n        # Random rotation\n        if random.random() > 0.5:\n            angle = random.randint(-30, 30)\n            image = TF.rotate(image, angle)\n            mask = TF.rotate(mask, angle)\n        \n        return image, mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T02:39:54.971337Z","iopub.execute_input":"2024-10-19T02:39:54.972184Z","iopub.status.idle":"2024-10-19T02:39:54.986911Z","shell.execute_reply.started":"2024-10-19T02:39:54.972118Z","shell.execute_reply":"2024-10-19T02:39:54.985664Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"img_path = '/kaggle/input/cosmo-segmentation/Segmentation dataset -20241018T225923Z-001/Segmentation dataset/Segmentation dataset/Image'\nmask_path = '/kaggle/input/cosmo-segmentation/Segmentation dataset -20241018T225923Z-001/Segmentation dataset/Segmentation dataset/Mask' \ncsv_path = '/kaggle/input/cosmo-segmentation/Segmentation dataset -20241018T225923Z-001/Segmentation dataset/Segmentation dataset/metadata.csv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T02:39:57.352645Z","iopub.execute_input":"2024-10-19T02:39:57.353085Z","iopub.status.idle":"2024-10-19T02:39:57.358392Z","shell.execute_reply.started":"2024-10-19T02:39:57.353042Z","shell.execute_reply":"2024-10-19T02:39:57.357318Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Subset\nfrom torchvision import transforms\n\n# Assuming we're using the FloodDataset class we defined earlier\n\n# Image transforms\nimg_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Mask transforms\nmask_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor()\n])\n\n# Create the full dataset\nfull_dataset = FloodDataset(\n    csv_file=csv_path, \n    img_dir=img_path, \n    mask_dir=mask_path, \n    img_transform=img_transform,\n    mask_transform=mask_transform,\n    augment=True  # We'll apply augmentation only to the training set later\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T02:46:55.596918Z","iopub.execute_input":"2024-10-19T02:46:55.598035Z","iopub.status.idle":"2024-10-19T02:46:55.621242Z","shell.execute_reply.started":"2024-10-19T02:46:55.597970Z","shell.execute_reply":"2024-10-19T02:46:55.619728Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"# Set the ratio for the validation set (e.g., 20% of the data)\nval_ratio = 0.2\n\n# Get the total number of samples\nnum_samples = len(full_dataset)\n\n# Generate indices for the split\nindices = list(range(num_samples))\n\n# Perform the split\ntrain_indices, val_indices = train_test_split(\n    indices, \n    test_size=val_ratio, \n    random_state=42  # Set a random state for reproducibility\n)\n\n# Create Subset objects for training and validation\ntrain_dataset = Subset(full_dataset, train_indices)\nval_dataset = Subset(full_dataset, val_indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T02:46:59.581875Z","iopub.execute_input":"2024-10-19T02:46:59.582292Z","iopub.status.idle":"2024-10-19T02:46:59.591412Z","shell.execute_reply.started":"2024-10-19T02:46:59.582251Z","shell.execute_reply":"2024-10-19T02:46:59.590202Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"class AugmentedSubset(Subset):\n    def __init__(self, dataset, indices, augment=False):\n        super().__init__(dataset, indices)\n        self.augment = augment\n\n    def __getitem__(self, idx):\n        image, mask = super().__getitem__(idx)\n        if self.augment:\n            # Apply augmentation\n            image, mask = self.dataset.apply_augmentation(image, mask)\n        return image, mask\n\n# Recreate our datasets with appropriate augmentation settings\ntrain_dataset = AugmentedSubset(full_dataset, train_indices, augment=True)\nval_dataset = AugmentedSubset(full_dataset, val_indices, augment=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T02:47:01.714437Z","iopub.execute_input":"2024-10-19T02:47:01.715606Z","iopub.status.idle":"2024-10-19T02:47:01.723201Z","shell.execute_reply.started":"2024-10-19T02:47:01.715546Z","shell.execute_reply":"2024-10-19T02:47:01.722102Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size = 16\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T02:47:04.887643Z","iopub.execute_input":"2024-10-19T02:47:04.888069Z","iopub.status.idle":"2024-10-19T02:47:04.894526Z","shell.execute_reply.started":"2024-10-19T02:47:04.888027Z","shell.execute_reply":"2024-10-19T02:47:04.893324Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DoubleConv, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n\nclass UNet(nn.Module):\n    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n        super(UNet, self).__init__()\n        self.downs = nn.ModuleList()\n        self.ups = nn.ModuleList()\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        # Down part of U-Net\n        for feature in features:\n            self.downs.append(DoubleConv(in_channels, feature))\n            in_channels = feature\n\n        # Up part of U-Net\n        for feature in reversed(features):\n            self.ups.append(\n                nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2)\n            )\n            self.ups.append(DoubleConv(feature*2, feature))\n\n        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n\n    def forward(self, x):\n        skip_connections = []\n\n        for down in self.downs:\n            x = down(x)\n            skip_connections.append(x)\n            x = self.pool(x)\n\n        x = self.bottleneck(x)\n        skip_connections = skip_connections[::-1]\n\n        for idx in range(0, len(self.ups), 2):\n            x = self.ups[idx](x)\n            skip_connection = skip_connections[idx//2]\n\n            if x.shape != skip_connection.shape:\n                x = torch.nn.functional.resize(x, size=skip_connection.shape[2:])\n\n            concat_skip = torch.cat((skip_connection, x), dim=1)\n            x = self.ups[idx+1](concat_skip)\n\n        return self.final_conv(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T02:47:47.384698Z","iopub.execute_input":"2024-10-19T02:47:47.385702Z","iopub.status.idle":"2024-10-19T02:47:47.403764Z","shell.execute_reply.started":"2024-10-19T02:47:47.385655Z","shell.execute_reply":"2024-10-19T02:47:47.402510Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Assuming we've already defined our UNet class\n\n# Set the device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Create the model and move it to the device\nmodel = UNet(in_channels=3, out_channels=1).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T02:49:59.216296Z","iopub.execute_input":"2024-10-19T02:49:59.217501Z","iopub.status.idle":"2024-10-19T02:49:59.538796Z","shell.execute_reply.started":"2024-10-19T02:49:59.217455Z","shell.execute_reply":"2024-10-19T02:49:59.537854Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\nlearning_rate = 1e-4\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T02:50:19.538406Z","iopub.execute_input":"2024-10-19T02:50:19.538793Z","iopub.status.idle":"2024-10-19T02:50:19.545685Z","shell.execute_reply.started":"2024-10-19T02:50:19.538757Z","shell.execute_reply":"2024-10-19T02:50:19.544426Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"import torch\n\ndef iou_score(outputs, targets, smooth=1e-6):\n    outputs = (outputs > 0.5).float()  # binarize the outputs\n    targets = (targets > 0.5).float()  # ensure targets are binary\n    \n    intersection = (outputs * targets).sum((1, 2))\n    union = outputs.sum((1, 2)) + targets.sum((1, 2)) - intersection\n    \n    iou = (intersection + smooth) / (union + smooth)\n    return iou.mean()\n\ndef dice_coefficient(outputs, targets, smooth=1e-6):\n    outputs = (outputs > 0.5).float()  # binarize the outputs\n    targets = (targets > 0.5).float()  # ensure targets are binary\n    \n    intersection = (outputs * targets).sum((1, 2))\n    union = outputs.sum((1, 2)) + targets.sum((1, 2))\n    \n    dice = (2. * intersection + smooth) / (union + smooth)\n    return dice.mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T03:05:14.566355Z","iopub.execute_input":"2024-10-19T03:05:14.567297Z","iopub.status.idle":"2024-10-19T03:05:14.577022Z","shell.execute_reply.started":"2024-10-19T03:05:14.567252Z","shell.execute_reply":"2024-10-19T03:05:14.575917Z"}},"outputs":[],"execution_count":90},{"cell_type":"code","source":"def train_one_epoch(model, loader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    for images, masks in loader:\n        images = images.to(device)\n        masks = masks.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, masks)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n    \n    return total_loss / len(loader)\n\ndef validate(model, loader, criterion, device):\n    model.eval()\n    total_loss = 0\n    total_iou = 0\n    total_dice = 0\n    num_batches = len(loader)\n    \n    with torch.no_grad():\n        for images, masks in loader:\n            images = images.to(device)\n            masks = masks.to(device)\n            \n            outputs = model(images)\n            loss = criterion(outputs, masks)\n            \n            # Apply sigmoid to get probabilities\n            outputs = torch.sigmoid(outputs)\n            \n            # Ensure outputs and masks have the same shape\n            outputs = outputs.squeeze(1)  # Remove channel dim if it exists\n            masks = masks.squeeze(1)  # Remove channel dim if it exists\n            \n            # Compute IoU and Dice\n            batch_iou = iou_score(outputs, masks)\n            batch_dice = dice_coefficient(outputs, masks)\n            \n            total_loss += loss.item()\n            total_iou += batch_iou.item()\n            total_dice += batch_dice.item()\n    \n    avg_loss = total_loss / num_batches\n    avg_iou = total_iou / num_batches\n    avg_dice = total_dice / num_batches\n    \n    return avg_loss, avg_iou, avg_dice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T03:05:43.390363Z","iopub.execute_input":"2024-10-19T03:05:43.390752Z","iopub.status.idle":"2024-10-19T03:05:43.402363Z","shell.execute_reply.started":"2024-10-19T03:05:43.390714Z","shell.execute_reply":"2024-10-19T03:05:43.401138Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"from torch.optim.lr_scheduler import ReduceLROnPlateau\n\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T03:41:10.446221Z","iopub.execute_input":"2024-10-19T03:41:10.446658Z","iopub.status.idle":"2024-10-19T03:41:10.452251Z","shell.execute_reply.started":"2024-10-19T03:41:10.446618Z","shell.execute_reply":"2024-10-19T03:41:10.451123Z"}},"outputs":[],"execution_count":100},{"cell_type":"code","source":"len(train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T03:38:27.772322Z","iopub.execute_input":"2024-10-19T03:38:27.772738Z","iopub.status.idle":"2024-10-19T03:38:27.781053Z","shell.execute_reply.started":"2024-10-19T03:38:27.772701Z","shell.execute_reply":"2024-10-19T03:38:27.779856Z"}},"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"232"},"metadata":{}}],"execution_count":97},{"cell_type":"code","source":"num_epochs = 25  # You've already trained for 25 epochs\nbest_val_loss = 0.2327  # Your best validation loss from previous training\n\nfor epoch in range(num_epochs):\n    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n    val_loss, val_iou, val_dice = validate(model, val_loader, criterion, device)\n    \n    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n          f\"Train Loss: {train_loss:.4f}, \"\n          f\"Val Loss: {val_loss:.4f}, \"\n          f\"Val IoU: {val_iou:.4f}, \"\n          f\"Val Dice: {val_dice:.4f}\")\n    \n    # Learning rate scheduling\n    scheduler.step(val_loss)\n    \n    # Save the best model\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), 'best_model.pth')\n        print(f\"Saved new best model with validation loss: {best_val_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T03:50:21.047279Z","iopub.execute_input":"2024-10-19T03:50:21.047746Z","iopub.status.idle":"2024-10-19T03:54:41.340113Z","shell.execute_reply.started":"2024-10-19T03:50:21.047701Z","shell.execute_reply":"2024-10-19T03:54:41.338736Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/25, Train Loss: 0.1859, Val Loss: 0.2386, Val IoU: 0.7781, Val Dice: 0.8661\nEpoch 2/25, Train Loss: 0.1878, Val Loss: 0.2468, Val IoU: 0.7740, Val Dice: 0.8645\nEpoch 3/25, Train Loss: 0.1891, Val Loss: 0.2451, Val IoU: 0.7763, Val Dice: 0.8656\nEpoch 4/25, Train Loss: 0.1849, Val Loss: 0.2379, Val IoU: 0.7773, Val Dice: 0.8664\nEpoch 5/25, Train Loss: 0.1856, Val Loss: 0.2387, Val IoU: 0.7777, Val Dice: 0.8662\nEpoch 6/25, Train Loss: 0.1854, Val Loss: 0.2442, Val IoU: 0.7789, Val Dice: 0.8675\nEpoch 7/25, Train Loss: 0.1832, Val Loss: 0.2457, Val IoU: 0.7775, Val Dice: 0.8668\nEpoch 8/25, Train Loss: 0.1867, Val Loss: 0.2355, Val IoU: 0.7772, Val Dice: 0.8656\nEpoch 9/25, Train Loss: 0.1832, Val Loss: 0.2324, Val IoU: 0.7851, Val Dice: 0.8729\nSaved new best model with validation loss: 0.2324\nEpoch 10/25, Train Loss: 0.1843, Val Loss: 0.2367, Val IoU: 0.7800, Val Dice: 0.8679\nEpoch 11/25, Train Loss: 0.1854, Val Loss: 0.2425, Val IoU: 0.7783, Val Dice: 0.8673\nEpoch 12/25, Train Loss: 0.1890, Val Loss: 0.2358, Val IoU: 0.7769, Val Dice: 0.8667\nEpoch 13/25, Train Loss: 0.1842, Val Loss: 0.2377, Val IoU: 0.7792, Val Dice: 0.8680\nEpoch 14/25, Train Loss: 0.1832, Val Loss: 0.2405, Val IoU: 0.7735, Val Dice: 0.8637\nEpoch 15/25, Train Loss: 0.1884, Val Loss: 0.2404, Val IoU: 0.7803, Val Dice: 0.8679\nEpoch 16/25, Train Loss: 0.1911, Val Loss: 0.2443, Val IoU: 0.7768, Val Dice: 0.8659\nEpoch 17/25, Train Loss: 0.1881, Val Loss: 0.2373, Val IoU: 0.7786, Val Dice: 0.8671\nEpoch 18/25, Train Loss: 0.1883, Val Loss: 0.2451, Val IoU: 0.7747, Val Dice: 0.8645\nEpoch 19/25, Train Loss: 0.1847, Val Loss: 0.2367, Val IoU: 0.7872, Val Dice: 0.8751\nEpoch 20/25, Train Loss: 0.1840, Val Loss: 0.2351, Val IoU: 0.7790, Val Dice: 0.8684\nEpoch 21/25, Train Loss: 0.1848, Val Loss: 0.2398, Val IoU: 0.7853, Val Dice: 0.8727\nEpoch 22/25, Train Loss: 0.1925, Val Loss: 0.2388, Val IoU: 0.7795, Val Dice: 0.8680\nEpoch 23/25, Train Loss: 0.1893, Val Loss: 0.2421, Val IoU: 0.7834, Val Dice: 0.8726\nEpoch 24/25, Train Loss: 0.1819, Val Loss: 0.2402, Val IoU: 0.7779, Val Dice: 0.8675\nEpoch 25/25, Train Loss: 0.1861, Val Loss: 0.2402, Val IoU: 0.7772, Val Dice: 0.8677\n","output_type":"stream"}],"execution_count":104},{"cell_type":"code","source":"current_lr = optimizer.param_groups[0]['lr']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T03:54:47.025182Z","iopub.execute_input":"2024-10-19T03:54:47.026096Z","iopub.status.idle":"2024-10-19T03:54:47.031792Z","shell.execute_reply.started":"2024-10-19T03:54:47.026050Z","shell.execute_reply":"2024-10-19T03:54:47.030719Z"}},"outputs":[],"execution_count":105},{"cell_type":"code","source":"model_path = '/kaggle/working/entire_model.pth'\ntorch.save(model, model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T03:59:33.481209Z","iopub.execute_input":"2024-10-19T03:59:33.481679Z","iopub.status.idle":"2024-10-19T03:59:33.729773Z","shell.execute_reply.started":"2024-10-19T03:59:33.481634Z","shell.execute_reply":"2024-10-19T03:59:33.728861Z"}},"outputs":[],"execution_count":107},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"current_lr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T03:54:48.681972Z","iopub.execute_input":"2024-10-19T03:54:48.683043Z","iopub.status.idle":"2024-10-19T03:54:48.689963Z","shell.execute_reply.started":"2024-10-19T03:54:48.682994Z","shell.execute_reply":"2024-10-19T03:54:48.688862Z"}},"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"1.0000000000000004e-08"},"metadata":{}}],"execution_count":106},{"cell_type":"code","source":"# Epoch 23/25, Train Loss: 0.2166, Val Loss: 0.2577, Val IoU: 0.7511, Val Dice: 0.8475\n# Epoch 24/25, Train Loss: 0.2080, Val Loss: 0.2499, Val IoU: 0.7688, Val Dice: 0.8613\n# Epoch 25/25, Train Loss: 0.2154, Val Loss: 0.2445, Val IoU: 0.7697, Val Dice: 0.8627\n# Saved new best model with validation loss: 0.2445","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Split dataset into training and validation sets (80% train, 20% validation)\n# train_size = int(0.8 * len(dataset))\n# val_size = len(dataset) - train_size\n# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n# # Create DataLoaders\n# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n# val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T02:15:44.618418Z","iopub.execute_input":"2024-10-19T02:15:44.618883Z","iopub.status.idle":"2024-10-19T02:15:44.626570Z","shell.execute_reply.started":"2024-10-19T02:15:44.618831Z","shell.execute_reply":"2024-10-19T02:15:44.625326Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"# dataiter = iter(train_loader)\n# images, masks = next(dataiter)\n\n# # Visualize the first image and mask in the batch with unnormalization\n# # visualize_sample(images[1], masks[1], mean, std)\n# images[1].type()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T02:15:44.958593Z","iopub.execute_input":"2024-10-19T02:15:44.959038Z","iopub.status.idle":"2024-10-19T02:15:44.963853Z","shell.execute_reply.started":"2024-10-19T02:15:44.958994Z","shell.execute_reply":"2024-10-19T02:15:44.962753Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import torchvision.transforms.functional as TF\n\n# # Define an unnormalization function to reverse the normalization\n# def unnormalize(tensor, mean, std):\n#     \"\"\"Reverses normalization for display purposes.\"\"\"\n#     for t, m, s in zip(tensor, mean, std):\n#         t.mul_(s).add_(m)  # Unnormalize the image (inplace)\n#     return tensor\n\n# def visualize_sample(image, mask, mean, std):\n#     # Unnormalize the image before visualizing\n#     image = unnormalize(image.clone(), mean, std)  # Clone so as not to modify the original tensor\n#     image = TF.to_pil_image(image)  # Convert tensor to PIL image\n#     mask = TF.to_pil_image(mask)    # Convert tensor to PIL grayscale image\n    \n#     # Plot side by side\n#     fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n    \n#     ax[0].imshow(image)\n#     ax[0].set_title(\"Image\")\n#     ax[0].axis(\"off\")\n    \n#     ax[1].imshow(mask, cmap=\"gray\")\n#     ax[1].set_title(\"Mask\")\n#     ax[1].axis(\"off\")\n    \n#     plt.show()\n\n\n# from torch.utils.data import DataLoader\n\n# # Mean and std used during normalization\n# mean = [0.485, 0.456, 0.406]\n# std = [0.229, 0.224, 0.225]\n\n# # Create DataLoader (assuming dataset is already defined)\n# dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n\n# # Get a batch of data\n# dataiter = iter(dataloader)\n# images, masks = next(dataiter)\n\n# # Visualize the first image and mask in the batch with unnormalization\n# visualize_sample(images[1], masks[1], mean, std)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T02:15:45.295121Z","iopub.execute_input":"2024-10-19T02:15:45.295537Z","iopub.status.idle":"2024-10-19T02:15:45.302206Z","shell.execute_reply.started":"2024-10-19T02:15:45.295496Z","shell.execute_reply":"2024-10-19T02:15:45.300861Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n\n# class UNet(nn.Module):\n#     def __init__(self):\n#         super(UNet, self).__init__()\n#         # Encoder (downsampling)\n#         self.enc1 = self.conv_block(3, 64)\n#         self.enc2 = self.conv_block(64, 128)\n#         self.enc3 = self.conv_block(128, 256)\n#         self.enc4 = self.conv_block(256, 512)\n#         self.enc5 = self.conv_block(512, 1024)\n        \n#         # Decoder (upsampling)\n#         self.upconv5 = self.upconv_block(1024, 512)\n#         self.dec5 = self.conv_block(1024, 512, pool=False)\n#         self.upconv4 = self.upconv_block(512, 256)\n#         self.dec4 = self.conv_block(512, 256, pool=False)\n#         self.upconv3 = self.upconv_block(256, 128)\n#         self.dec3 = self.conv_block(256, 128, pool=False)\n#         self.upconv2 = self.upconv_block(128, 64)\n#         self.dec2 = self.conv_block(128, 64, pool=False)\n#         self.upconv1 = self.upconv_block(64, 32)\n#         self.dec1 = self.conv_block(35, 64, pool=False)\n        \n#         self.final = nn.Conv2d(64, 1, kernel_size=1)\n\n#     def conv_block(self, in_channels, out_channels, pool=True):\n#         layers = [\n#             nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n#             nn.ReLU(inplace=True),\n#             nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n#             nn.ReLU(inplace=True)\n#         ]\n#         if pool:\n#             layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n#         return nn.Sequential(*layers)\n\n#     def upconv_block(self, in_channels, out_channels):\n#         return nn.Sequential(\n#             nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n#             nn.ReLU(inplace=True)\n#         )\n\n#     def forward(self, x):\n#         # Encoding\n#         e1 = self.enc1(x)\n#         e2 = self.enc2(e1)\n#         e3 = self.enc3(e2)\n#         e4 = self.enc4(e3)\n#         e5 = self.enc5(e4)\n        \n#         # Decoding\n#         d5 = self.upconv5(e5)\n#         d5 = torch.cat([d5, e4], dim=1)\n#         d5 = self.dec5(d5)\n        \n#         d4 = self.upconv4(d5)\n#         d4 = torch.cat([d4, e3], dim=1)\n#         d4 = self.dec4(d4)\n        \n#         d3 = self.upconv3(d4)\n#         d3 = torch.cat([d3, e2], dim=1)\n#         d3 = self.dec3(d3)\n        \n#         d2 = self.upconv2(d3)\n#         d2 = torch.cat([d2, e1], dim=1)\n#         d2 = self.dec2(d2)\n        \n#         d1 = self.upconv1(d2)\n#         d1 = torch.cat([d1, x], dim=1)\n#         d1 = self.dec1(d1)\n        \n#         out = self.final(d1)\n#         return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T02:15:45.674031Z","iopub.execute_input":"2024-10-19T02:15:45.675436Z","iopub.status.idle":"2024-10-19T02:15:45.695273Z","shell.execute_reply.started":"2024-10-19T02:15:45.675387Z","shell.execute_reply":"2024-10-19T02:15:45.694240Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"# model = UNet()\n# input_tensor = torch.randn(16, 3, 256, 256)\n# output = model(input_tensor)\n# print(\"Final output shape:\", output.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T01:43:33.354276Z","iopub.execute_input":"2024-10-19T01:43:33.355286Z","iopub.status.idle":"2024-10-19T01:43:33.359841Z","shell.execute_reply.started":"2024-10-19T01:43:33.355242Z","shell.execute_reply":"2024-10-19T01:43:33.358599Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n\n# # Initialize the model (UNet in this case)\n# model = UNet()\n# model = model.to(device)  # Send the model to the GPU if available\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T02:15:57.534570Z","iopub.execute_input":"2024-10-19T02:15:57.535033Z","iopub.status.idle":"2024-10-19T02:15:57.831350Z","shell.execute_reply.started":"2024-10-19T02:15:57.534990Z","shell.execute_reply":"2024-10-19T02:15:57.829864Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"# # Loss function (binary cross-entropy)\n# criterion = nn.BCEWithLogitsLoss()\n\n# # Optimizer\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# # IoU metric function\n# def iou_score(output, target):\n#     smooth = 1e-6\n#     output = torch.sigmoid(output)  # Convert logits to probabilities\n#     output = (output > 0.5).float()  # Threshold\n#     intersection = (output * target).sum()\n#     union = output.sum() + target.sum() - intersection\n#     return (intersection + smooth) / (union + smooth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T02:15:59.540455Z","iopub.execute_input":"2024-10-19T02:15:59.540949Z","iopub.status.idle":"2024-10-19T02:15:59.549981Z","shell.execute_reply.started":"2024-10-19T02:15:59.540900Z","shell.execute_reply":"2024-10-19T02:15:59.548778Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# num_epochs = 40  # Set the number of epochs\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n\n# for epoch in range(num_epochs):\n#     model.train()  # Set model to training mode\n#     train_loss = 0\n#     train_iou = 0\n\n#     # Training loop\n#     for images, masks in train_loader:\n#         images, masks = images.to(device), masks.to(device)\n\n#         masks = masks.float()\n#         # Zero the gradients\n#         optimizer.zero_grad()\n        \n#         # Forward pass\n#         outputs = model(images)\n#         loss = criterion(outputs, masks)\n        \n#         # Backward pass\n#         loss.backward()\n#         optimizer.step()\n        \n#         train_loss += loss.item()\n#         train_iou += iou_score(outputs, masks).item()\n\n#     # Average training loss and IoU over all batches\n#     train_loss /= len(train_loader)\n#     train_iou /= len(train_loader)\n    \n#     print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Train IoU: {train_iou}')\n    \n#     # Validation loop\n#     model.eval()  # Set model to evaluation mode\n#     val_loss = 0\n#     val_iou = 0\n#     with torch.no_grad():  # No gradient calculation needed during validation\n#         for images, masks in val_loader:\n#             images, masks = images.to(device), masks.to(device)\n#             masks = masks.float()\n#             outputs = model(images)\n#             loss = criterion(outputs, masks)\n#             val_loss += loss.item()\n#             val_iou += iou_score(outputs, masks).item()\n\n#     # Average validation loss and IoU over all batches\n#     val_loss /= len(val_loader)\n#     val_iou /= len(val_loader)\n    \n#     print(f'Epoch {epoch+1}/{num_epochs}, Val Loss: {val_loss}, Val IoU: {val_iou}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T02:19:48.644554Z","iopub.execute_input":"2024-10-19T02:19:48.645003Z","iopub.status.idle":"2024-10-19T02:20:17.546543Z","shell.execute_reply.started":"2024-10-19T02:19:48.644959Z","shell.execute_reply":"2024-10-19T02:20:17.545219Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/40, Train Loss: -1.8434028711925926e+23, Train IoU: 100.96084340413411\nEpoch 1/40, Val Loss: -7.615329724272793e+23, Val IoU: 116.52462768554688\nEpoch 2/40, Train Loss: -1.2076013001555804e+24, Train IoU: 99.70483601888021\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[71], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m val_iou \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# No gradient calculation needed during validation\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, masks \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[1;32m     40\u001b[0m         images, masks \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), masks\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     41\u001b[0m         masks \u001b[38;5;241m=\u001b[39m masks\u001b[38;5;241m.\u001b[39mfloat()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","Cell \u001b[0;32mIn[60], line 25\u001b[0m, in \u001b[0;36mFloodSegmentationDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     22\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Convert image to RGB\u001b[39;00m\n\u001b[1;32m     23\u001b[0m mask \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(mask_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Convert mask to grayscale\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(mask)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Apply transformations\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":71},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}